{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b90167-fadd-4117-bfc6-00ca965fa285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e593be-30b7-4594-87e9-b4858b5779b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.read_csv('features.csv',skiprows = 1).dropna(subset = ['Variable Name'])\n",
    "var_df.index=var_df['Variable Name']\n",
    "var_df['Variable Type'].drop_duplicates()\n",
    "var_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34776b52-758d-4aac-9127-9291426441e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [r[1]['Variable Name'] for r in var_df.iterrows() if r[1]['feature'] == 1]\n",
    "target = [r[1]['Variable Name'] for r in var_df.iterrows() if r[1]['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18142bab-81ca-4d78-8d4f-04581e3bbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "for r in var_df.iterrows():\n",
    "    if r[1]['Variable Type'] == 'Categorical':\n",
    "        dtypes[r[1]['Variable Name']] = 'category'\n",
    "    else:\n",
    "        dtypes[r[1]['Variable Name']] = 'float'\n",
    "dtypes_features = {k:v for k,v in dtypes.items() if k in feature_list}\n",
    "with open('dtypes_features.yaml','w') as dtf:\n",
    "    yaml.dump(dtypes_features,dtf,default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d86a5-9171-4b6d-a817-bf36819c2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv',dtype = dtypes)\n",
    "data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f85ec7-83d2-4c69-8fa2-8a7f6b8b4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(data.columns) == set(feature_list))\n",
    "set(data.columns).symmetric_difference(set(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f631d1-3004-4aea-96e7-b24013596def",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data.columns).difference(set(feature_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd8c8f-e6b2-4cdc-b1ea-a6c3c4746430",
   "metadata": {},
   "source": [
    "The symmetric difference of the data columns and feature list shows that MALE_MAR_or_WID needs to change to 'MALE_MAR_WID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d7887-0637-4ebb-a7f4-8d64be272577",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'MALE_MAR_or_WID':'MALE_MAR_WID'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d82227-5621-40c3-a447-65bbd6f23b41",
   "metadata": {},
   "source": [
    "Extract X and y variables. Make training and testing set for benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea1138-2eee-4fe9-b78a-12d7c7fdbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[feature_list]\n",
    "y = data[target]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size= .2, random_state=10) #Set random state for consistent benchmarking\n",
    "X_tr.to_csv('X_tr.csv',index = False)\n",
    "X_te.to_csv('X_te.csv',index = False)\n",
    "y_tr.to_csv('y_tr.csv', index = False)\n",
    "y_te.to_csv('y_te.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea5ec8-9d96-4572-9e28-a5f229cfc7bf",
   "metadata": {},
   "source": [
    "There are no NA, therefore no (immediate) reason to impute values.\n",
    "# Logistic regression model\n",
    "* 10-fold Cross validate with grid search. It is a small data set so random search/ bayesian hyperparameter optimization is overkill\n",
    "* Transforms:\n",
    "  * One hot encode categorical variables.\n",
    "  * Binary variables should be scaled to 0 or 1.\n",
    "  * Numeric will be made approximately normal using Yeo-Johnson transform (sklearn power transform) as a monotone transform making data closer N(0,1). This transform is capable of taking the log(x + 1)-transform when appropriate (for $ amount variables and other >= variable). \n",
    "  * FeatureUnion creates one transform for all columns by name.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00755b02-f5e1-4348-aeab-87d762c3a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = feature_list[0]\n",
    "feature_types = {f:var_df.loc[f,'Variable Type'] for f in feature_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218cf6b-4105-46a8-af49-581146b48eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules needed for logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, MinMaxScaler, KBinsDiscretizer, Binarizer, RobustScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, make_scorer,  roc_auc_score\n",
    "from sklearn.impute  import SimpleImputer\n",
    "#\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display = 'diagram')\n",
    "col_transformers = []\n",
    "for k, v in feature_types.items():\n",
    "    if k == 'AMOUNT':\n",
    "        continue\n",
    "    if v == 'Numerical':\n",
    "        col_transformers += [('power_'+k,PowerTransformer(),[k])]\n",
    "    if v == 'Categorical':\n",
    "        col_transformers += [('onehot_'+k,OneHotEncoder(),[k])]\n",
    "    if v == 'Binary':\n",
    "        col_transformers += [('binary_'+k,MinMaxScaler(),[k])]\n",
    "col_transformers += [('scaler_'+'AMOUNT',RobustScaler(),['AMOUNT'])]\n",
    "ColumnTransformer(col_transformers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae21667-e3c1-4fe3-8855-b456f29a3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interact_last(X):\n",
    "    return np.c_[X[:,:-5]*X[:,-5:-4],X[:,:-5]*X[:,-4:-3],X[:,:-5]*X[:,-3:-2],X[:,:-5]*X[:,-2:-1],X[:,:-5]*X[:,-1:]]\n",
    "def func_feature_name(transformer, feature_names):\n",
    "    return feature_names[:-1]\n",
    "\n",
    "\n",
    "\n",
    "feature_transform.fit_transform(X_tr)\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "interaction_transformer = FeatureUnion([('',FunctionTransformer(func = None,feature_names_out='one-to-one')),\n",
    "                            ('AMT',Pipeline([('multamt',FunctionTransformer(func = interact_last,feature_names_out=func_feature_name)),\n",
    "                                            ('impute0',SimpleImputer(strategy = 'mean',missing_values = 0)),\n",
    "                                            ('scale',StandardScaler())]))])\n",
    "\n",
    "feature_transformer = Pipeline([('transforms',ColumnTransformer(col_transformers,remainder = 'drop',verbose_feature_names_out=False))])\n",
    "\n",
    "logistic_model = Pipeline([('feature_transformer',feature_transformer),\n",
    "                           ('logistic_regression',LogisticRegression(penalty = 'elasticnet',solver = 'saga'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b45787-b481-404e-b2d4-394eb90101e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07df01-d6f4-4397-a8d4-1340ecfa5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_scorer = make_scorer(log_loss,greater_is_better=False,needs_proba=True)\n",
    "auc_scorer = make_scorer(roc_auc_score,greater_is_better=True,needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d863f-2a98-4daf-9a41-911043578f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10,shuffle=True, random_state= 10)\n",
    "logistic_model_cv = GridSearchCV(logistic_model,\n",
    "                                 param_grid = {'logistic_regression__C': np.logspace(-4,4,10), 'logistic_regression__l1_ratio': np.linspace(0,1,10)},\n",
    "                                 verbose=True,\n",
    "                                 \n",
    "                                 scoring= ['neg_log_loss', 'roc_auc'],\n",
    "                                 cv= skf,\n",
    "                                 refit = 'neg_log_loss',\n",
    "                                 n_jobs = -1\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a68bfa-5d68-4d3c-86df-2aded307dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_cv.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b66710-b2ec-4d0c-89f1-1559b0966fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr['DURATION'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b65ec-565c-4713-bffd-9ba67ad721f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "with open(\"logistic_pipeline.html\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(estimator_html_repr(logistic_model_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623bd2a-3a6b-4cc9-977f-53fa46b75c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff48f6-3b42-4ebc-98e2-33b288d8dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0ed30-eb8f-498b-bf40-2769ef358de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame.from_dict(logistic_model_cv.cv_results_)\n",
    "cv_results.sort_values(by='rank_test_neg_log_loss').to_csv('logistic_regression_CV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6686f3-74e1-4827-b55e-9433892be020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(logistic_model_cv,'logistic_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ceb90-510f-4419-89fb-94d05f132197",
   "metadata": {},
   "source": [
    "## test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d9dbe-1a4c-401d-914c-00b6084027eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_pred=logistic_model_cv.predict_proba(X_te)[:,1],y_true=y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e7878-85ec-4a36-8d82-83664c5b14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_score=logistic_model_cv.predict_proba(X_te)[:,1],y_true=y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e63a4-3126-48aa-95ae-a12c697c45c8",
   "metadata": {},
   "source": [
    "# Gradient Boosted decision trees\n",
    "* Pros: Do not need to scale date\n",
    "* Cons: Difficult to interpret. Might not extrapolate to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24378d5-60ae-4f09-b42a-ed49043944ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules needed for tree-ensemble\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "#\n",
    "\n",
    "\n",
    "param_dist = {'base_estimator__max_depth': [2**i for i in range(5)],\n",
    "              'base_estimator__num_iterations':[50,100,200,400],\n",
    "              'base_estimator__reg_lambda':np.logspace(-3,3),\n",
    "              'base_estimator__learning_rate':np.logspace(-2,-.5),\n",
    "             'base_estimator__feature_fraction':[.25,.5,1.],\n",
    "             'base_estimator__bagging_freq':[0,1,5,10],\n",
    "              'base_estimator__bagging_fraction':[1.]\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gbdt_model_cv = RandomizedSearchCV(CalibratedClassifierCV(lgb.LGBMClassifier(boosting_type = 'dart',\n",
    "                                                                            interaction_constraints = \n",
    "                                                                             [[i for i,_ in enumerate(X_tr.columns) if _ !='DURATION'],\n",
    "                                                                              [i for i,_ in enumerate(X_tr.columns) if _ =='DURATION']],\n",
    "                                                                             monotone_constraints_method = 'advanced',\n",
    "                                                                            monotone_constraints = [int(x in ['AMOUNT','DURATION']) for x in X_tr.columns])),\n",
    "                                   n_iter=64,\n",
    "                                   param_distributions = param_dist, \n",
    "                                   cv = skf,scoring= ['neg_log_loss', 'roc_auc'],refit = 'neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca748b6-1695-4a74-87b4-4140a83ac090",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_model_cv.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f66bf2-30c5-4702-9a11-17bb24d80e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_model_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f995d7a-8ba4-4ce1-8ede-bca603d801a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_gbdt = pd.DataFrame.from_dict(gbdt_model_cv.cv_results_)\n",
    "cv_results_gbdt.sort_values(by='rank_test_neg_log_loss').to_csv('gbdt_CV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17136e95-c838-450f-a961-03a9b397225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_pred=gbdt_model_cv.predict_proba(X_te)[:,1],y_true=y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb1046-2978-4c61-aa34-435d9784da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_score=gbdt_model_cv.predict_proba(X_te)[:,1],y_true=y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918650f-f0db-4253-a926-b4b645d66f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gbdt_model_cv,'gbdt_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc26c0-37a5-4412-bbf1-913019872d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gbdt_pipeline.html\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(estimator_html_repr(gbdt_model_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f281c0-d7af-419f-b022-123d16a7bab5",
   "metadata": {},
   "source": [
    "# Random forest\n",
    "Do not use. One tree ensemble model is enough for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c6f2e-a8e3-4051-bb4b-a21f35a8f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = {'base_estimator__max_depth': range(1,10),\n",
    "              'base_estimator__num_iterations':[500],\n",
    "              'base_estimator__reg_lambda':np.logspace(-3,3),\n",
    "             'base_estimator__feature_fraction_bynode':[.2],\n",
    "              'base_estimator__bagging_freq':[1],\n",
    "             'base_estimator__bagging_fraction':[.9]}\n",
    "\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "rf_model_cv = RandomizedSearchCV(CalibratedClassifierCV(lgb.LGBMClassifier(boosting_type = 'rf')),\n",
    "                                   n_iter=64,\n",
    "                                   param_distributions = param_dist, \n",
    "                                   cv = skf,scoring =['neg_log_loss', 'roc_auc'],refit = 'neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fbed9-d332-4dd1-9edc-45a96f375e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_cv.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d45d18-fbd0-4fb7-a50f-b1cb9a145283",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796110f3-2b03-4971-912f-817a6f7c69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_rf = pd.DataFrame.from_dict(rf_model_cv.cv_results_)\n",
    "cv_results_rf.sort_values(by='rank_test_score').to_csv('rf_CV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178d999-7396-499e-ba35-32c91fde044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_pred=rf_model_cv.predict_proba(X_te)[:,1],y_true=y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d61b3-ab23-4f27-acc5-c7c3c12f8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_score=rf_model_cv.predict_proba(X_te)[:,1],y_true=y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec1db3c-f59b-4c10-9a0a-914de40ec2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
